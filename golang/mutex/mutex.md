# Mutex、RWMutex锁



## Mutex
mutex几种状态

- `mutexLocked` — 表示互斥锁的锁定状态；
- `mutexWoken` — 表示从正常模式被从唤醒；
- `mutexStarving` — 当前的互斥锁进入饥饿状态；
- `waitersCount` — 当前互斥锁上等待的 Goroutine 个数；

**正常模式(非公平锁)**

正常模式下，所有等待锁的goroutine按照FIFO(先进先出)顺序等待。唤醒的goroutine不会直接拥有锁，而是会和新请求锁的goroutine竞争锁的拥有。新请求锁的goroutine具有优势：它正在CPU上执行，而且可能有好几个，所以刚刚唤醒的goroutine有很大可能在锁竞争中失败。在这种情况下，这个被唤醒的goroutine会加入到等待队列的前面。 如果一个等待的goroutine超过1ms没有获取锁，那么它将会把锁转变为饥饿模式。

**饥饿模式(公平锁)**

为了解决了等待G队列的长尾问题
饥饿模式下，直接由unlock把锁交给等待队列中排在第一位的G(队头)，同时，饥饿模式下，新进来的G不会参与抢锁也不会进入自旋状态，会直接进入等待队列的尾部,这样很好的解决了老的g一直抢不到锁的场景。

饥饿模式的触发条件，当一个G等待锁时间超过1毫秒时，或者当前队列只剩下一个g的时候，Mutex切换到饥饿模式。

**总结**

对于两种模式，正常模式下的性能是最好的，goroutine可以连续多次获取锁，饥饿模式解决了取锁公平的问题，但是性能会下降，其实是性能和公平的一个平衡模式。

**补充**

- 允许自旋的条件

  1 锁已被占用，并且锁不处于饥饿模式。

  2 积累的自旋次数小于最大自旋次数（active_spin=4）。

  3 cpu核数大于1。

  4 有空闲的P。

  5 当前goroutine所挂载的P下，本地待运行队列为空。
  
  

## RWMutex

通过记录readerCount 读锁的数量来进行控制，当有一个写锁的时候，会将读锁数量设置为负数1<<30。目的是让新进入的读锁等待写锁之后释放通知读锁。同样的写锁也会等等待之前的读锁都释放完毕，才会开始进行后续的操作。 而等写锁释放完之后，会将值重新加上1<<30, 并通知刚才新进入的读锁(rw.readerSem)，两者互相限制



## Mutex如何避免内存重排

上边提到的`LOCK`指令及`XCHG`等指令，会引入内存屏障（`memory barrier`）

内存屏障是强制处理器按照可预知的方式访问内存的CPU指令。



### 





### COW(copy on write)

### 1 fork ##

- 子进程产生时, 父子进程共享数据内存, 子进程只读数据, 而父进程会持续服务客户端, 对数据进行修改
- 当父进程修改数据时, 会对修改的数据段页面产生 copy, 对这个复制出来的页面进行修改.
- 此时子进程中相应的页面是没有变化的.
- 当子进程备份完毕后, 这将 copy 出来的页面替换原来的页面

#### 1.1 redis fork处理

a、fork子进程，fork这个瞬间一定是会阻塞主线程的，fork采用操作系统提供的写实复制(Copy On Write)机制，就是为了避免一次性拷贝大量内存数据给子进程造成的长时间阻塞问题，但fork子进程需要拷贝进程必要的数据结构，其中有一项就是拷贝内存页表（虚拟内存和物理内存的映射索引表），这个拷贝过程会消耗大量CPU资源，拷贝完成之前整个进程是会阻塞的，阻塞时间取决于整个实例的内存大小，实例越大，内存页表越大，fork阻塞时间越久。拷贝内存页表完成后，子进程与父进程指向相同的内存地址空间，也就是说此时虽然产生了子进程，但是并没有申请与父进程相同的内存大小。那什么时候父子进程才会真正内存分离呢？“写实复制”顾名思义，就是在写发生时，才真正拷贝内存真正的数据，这个过程中，父进程也可能会产生阻塞的风险，就是下面介绍的场景。

b、fork出的子进程指向与父进程相同的内存地址空间，此时子进程就可以执行AOF重写，把内存中的所有数据写入到AOF文件中。但是此时父进程依旧是会有流量写入的，如果父进程操作的是一个已经存在的key，那么这个时候父进程就会真正拷贝这个key对应的内存数据，申请新的内存空间，这样逐渐地，父子进程内存数据开始分离，父子进程逐渐拥有各自独立的内存空间。因为内存分配是以页为单位进行分配的，默认4k，如果父进程此时操作的是一个bigkey，重新申请大块内存耗时会变长，可能会产阻塞风险。另外，如果操作系统开启了内存大页机制(Huge Page，页面大小2M)，那么父进程申请内存时阻塞的概率将会大大提高，所以在Redis机器上需要关闭Huge Page机制。Redis每次fork生成RDB或AOF重写完成后，都可以在Redis log中看到父进程重新申请了多大的内存空间。 

总结：fork子进程时，子进程是会拷贝父进程的页表，即虚实映射关系，而不会拷贝物理内存。子进程复制了父进程页表，也能共享访问父进程的内存数据了，此时，类似于有了父进程的所有内存数据

### 2 java CopyOnWriteArrayList ###

在增加和删除的时候都上锁，并且复制一份原来的数据，进行修改。之后在替换原先的array。可以看到get(int index)不需要加锁，因为CopyOnWriteArrayList在add/remove操作时，不会修改**原数组**，所以读操作不会存在线程安全问题。这其实就是**读写分离**的思想，只有写入的时候才加锁，复制副本来进行修改。CopyOnWriteArrayList也叫**写时复制**容器。  如果在c++，交换的时候，加锁，读的时候，获取不加锁，是有问题的。因为读旧的数据，一般已经被垃圾回收了，没有gc所以实现不了。

`亮点`：

1 [volatile](https://blog.csdn.net/ThinkWon/article/details/102243670)修饰的变量给Java虚拟机特殊的约定，线程对volatile变量的修改会立刻被其他线程所感知，即不会出现数据脏读的现象，从而保证数据的“可见性”。

#### volatile作用

- 它确保指令重排序时不会把其后面的指令排到内存屏障之前的位置，也不会把前面的指令排到内存屏障的后面；即在执行到内存屏障这句指令时，在它前面的操作已经全部完成；

- 它会强制将对缓存的修改操作立即写入主存；

- 如果是写操作，它会导致其他CPU中对应的缓存行无效。

2 内存占用问题, double的量，gc问题

3 数据一致性问题

### rcu(Read-Copy Update)锁

读不加锁，写者修改数据前首先拷贝一个被修改元素的副本，然后在副本上进行修改，修改完毕后它向垃圾回收器注册一个回调函数以便在适当的时机执行真正的修改操作。 包含的数据通常都是指针类型的，每个核上都发生过调度就说明如果其他核在该rcu锁的读临界区，完成一轮调度后（读临界区不可抢占）

如果再有新的线程可见的数据是新的老版本的可以释放了。如果是可抢占的RCU就需要在锁定开头和释放的结尾维护一个计数器。 (mosn就是这样实现)

cpu的指令重排 

内存屏障，CPU提供了 barrier指令

如果指定指令执行的顺序

[自旋锁实现方式](http://www.pydevops.com/2016/11/23/go%E8%87%AA%E6%97%8B%E9%94%81%E6%BA%90%E7%A0%81%E5%89%96%E6%9E%90/)


### 

### 常见坑点

- sync.mutex不可重入
- 不要拷贝锁，mutex做函数参数时，传参时使用指针。
- 死锁不是触发panic的充分条件

## Reference

[golang中的锁源码实现](http://legendtkl.com/2016/10/23/golang-mutex/)

[很细，mutex中runtime队列说法](http://birjemin.com/wiki/go-lock2)

[CopyOnWriteArrayList的原理和使用方法](https://www.jianshu.com/p/3e76450e58a8)

