### https加密过程

1. 客户端请求服务器获取`证书公钥`
2. 客户端(SSL/TLS)解析证书（无效会弹出警告）
3. 生成随机值
4. 用`公钥加密`随机值生成**密钥**
5. 客户端将`秘钥`发送给服务器
6. 服务端用`私钥`解密`秘钥`得到随机值
7. `将信息和随机值混合在一起`进行对称加密
8. 将加密的内容发送给客户端
9. 客户端用`秘钥`解密信息

- 验证证书

1. 客户端获取到了站点证书，拿到了站点的公钥
2. 客户端找到其站点证书颁发者的信息
3. `站点证书的颁发者`验证`服务端站点`是否可信
4. 往上回溯，找到`根证书颁发者`
5. 通过`根证书颁发者`一步步验证`站点证书颁布者`是否可信

### https一定安全吗

如果有一个假基站(中间服务器)，它会下方自己的伪造的证书给客户端。如果客户端信任了，那就会被中间服务器监听窃取了。但是通常这个浏览器会报证书伪造非法。但是如果客户端不小心点击信任，或者电脑中毒了。那么后续的https请求都是不安全了。

### 对称与非对称加密算法的区别

对称加密：加密和解密使用相同的密钥进行加密。常见的加密算法有`AES`,`3DES`,`DES`,`RC5`,`RC6`等

非对称加密：非对称加密算法需要两个密钥，公开密钥和私有密钥。公钥对数据进行加密的时候，只能通过对应的私钥才能解密。常见的非对称加密算法有`RSA`,`Elgamal`,`DSA`,`D-H`,`ECC`

### http1.1和http2.0区别

HTTP/1.1 的持久连接和管道机制允许复用TCP连接，在一个TCP连接中，也可以同时发送多个请求，但是所有的数据通信都是按次序完成的，服务器只有处理完一个回应，才会处理下一个回应。比如客户端需要A、B两个资源，管道机制(pipelining)允许浏览器同时发出A请求和B请求，但服务器还是按照顺序，先回应A请求，完成后再回应B请求，这样如果前面的回应特别慢，后面就会有很多请求排队等着，这称为“队头阻塞（Head-of-line blocking）”。分为请求对头阻塞和响应对头阻塞

2.0之前解决队头阻塞问题:

- 使用多个域名 

- 引入雪碧图  
- 将小图内联

## **HTTP/2**

HTTP/2 是如何解决HTTP/1.1 性能瓶颈的？使用Stream ID 来标识当前数据流属于哪个资源请求。HTTP/2以Google发布的SPDY协议为基础，于2015年发布。它不叫HTTP/2.0，因为标准委员会不打算再发布子版本了，下一个新版本将是HTTP/3。HTTP/2协议只在HTTPS环境下才有效，升级到HTTP/2，必须先启用HTTPS。HTTP/2解决了HTTP/1.1的性能问题，主要特点如下：

1. 二进制分帧：HTTP/1.1的头信息是文本（ASCII编码），数据体可以是文本，也可以是二进制；HTTP/2 头信息和数据体都是二进制，统称为“帧”：头信息帧和数据帧；
2. 多路复用（双工通信）：多路复用很好地解决了浏览器限制同一个域名下请求数量的问题，同时也更容易实现全速传输。通过单一的 HTTP/2 连接发起多重的请求-响应消息，即在`一个连接`里，客户端和浏览器都可以同时发送多个请求和响应，而不用按照顺序一一对应，这样避免了“队头堵塞”。HTTP/2 把 HTTP 协议通信的基本单位缩小为一个一个的帧，这些帧对应着逻辑流中的消息。并行地在同一个 TCP 连接上双向交换消息。
3. 数据流：因为 HTTP/2 的数据包是不按顺序发送的，同一个连接里面连续的数据包，可能属于不同的回应。因此，必须要对数据包做标记，指出它属于哪个回应。HTTP/2 将每个请求或回应的所有数据包，称为一个数据流（stream）。每个数据流都有一个独一无二的**编号**。数据包发送的时候，都必须标记数据流ID，用来区分它属于哪个数据流。另外还规定，客户端发出的数据流，ID一律为奇数，服务器发出的，ID为偶数。数据流发送到一半的时候，客户端和服务器都可以发送信号（`RST_STREAM`帧），取消这个数据流。HTTP/1.1取消数据流的唯一方法，就是关闭TCP连接。这就是说，HTTP/2 可以取消某一次请求，同时保证TCP连接还打开着，可以被其他请求使用。客户端还可以指定数据流的优先级。优先级越高，服务器就会越早回应。
4. 首部压缩：HTTP 协议不带有状态，每次请求都必须附上所有信息。所以，请求的很多字段都是重复的，，一模一样的内容，每次请求都必须附带，这会浪费很多带宽，也影响速度。HTTP/2 对这一点做了优化，引入了头信息压缩机制（header compression）。一方面，头信息压缩后再发送（SPDY 使用的是通用的DEFLATE 算法，而 HTTP/2 则使用了专门为首部压缩而设计的 HPACK 算法）。；另一方面，客户端和服务器同时维护一张头信息表，所有字段都会存入这个表，生成一个索引号，以后就不发送同样字段了，只发送索引号，这样就提高速度了。
5. 服务端推送：HTTP/2 允许服务器未经请求，主动向客户端发送资源，这叫做服务器推送（server push）。常见场景是客户端请求一个网页，这个网页里面包含很多静态资源。正常情况下，客户端必须收到网页后，解析HTML源码，发现有静态资源，再发出静态资源请求。其实，服务器可以预期到客户端请求网页后，很可能会再请求静态资源，所以就主动把这些静态资源随着网页一起发给客户端了。

### HTTP/2 还会队头阻塞吗?

HTTP/2 也存在队头阻塞问题，比如丢包。因为h2是基于TCP协议来传输的，tcp是字节流协议，必须保证收到的字节数据是完整且连续的。这样内核才会将缓冲区的数据返回给http应用层，那么当(前1个字节数据)没有到达时，后收到的字节数据只能存放到内核缓冲区，只有等待这个1字节数据到达时，h2应用层才能从内核拿到数据。这就是h2中tcp的对头阻塞的问题。而h1是属于http层的对头阻塞问题。

如果造成队头阻塞，问题可能比http1.1还严重，因为只有一个tcp连接，后续的传输都要等前面，http/1.1 多个tcp连接，阻塞一个，其他的还可以正常跑。

**HTTP/2下还会拥塞吗?**

由于 TCP 连接减少而使网络拥塞状况得以改观;

慢启动时间减少，拥塞和丢包恢复速度更快。

### http3.0技术

虽然tcp采用了滑动窗口来提高传输速率，但是当网络超时等问题，还会使窗口消耗殆尽，这样TCP 在传输层依然存在队头阻塞问题。 
**QUIC 使用的Packet Number 单调递增的设计，可以让数据包不再像TCP 那样必须有序确认，QUIC 支持乱序确认，当数据包Packet N 丢失后，只要有新的已接收数据包确认，当前窗口就会继续向右滑动**。

**有了Stream Offset 字段信息，属于同一个Stream ID 的数据包也可以乱序传输了**（HTTP/2 中仅靠Stream ID 标识，要求同属于一个Stream ID 的数据帧必须有序传输）

总结：QUIC 通过单向递增的Packet Number，配合Stream ID 与 Offset 字段信息，可以支持非连续确认应答Ack而不影响数据包的正确组装，摆脱了TCP 必须按顺序确认应答Ack 的限制（也即不能出现非连续的空位），解决了TCP 因某个数据包重传而阻塞后续所有待发送数据包的问题（也即队头阻塞问题）。

### tcp和ip协议区别

IP 协议和 TCP 协议虽然都会对数据进行拆分，但是 IP 协议以数据包（Package）为单位组织数据，而 TCP 协议以数据段（Segment）为单位组织数据。

### 为什么是三次握手？不是两次、四次？

- 避免历史连接

如果是两次连接，服务端在收到 SYN 报文后，就进入 ESTABLISHED 状态。这意味可以立刻给客户端发送数据。但是客户端网络阻塞，发了两次SYN报文，需要确认第二次的ack+序列号。但是服务端收到第一次报文，就回复了 并发送数据了。这时候客户端判断第一次报文，不是第二次的报文。就回复rst连接中止。这样旧的历史连接就会导致服务端建立了一个历史连接，又白白发送了数据，妥妥地浪费了服务端的资源。

**那三次握手，第三次客户端回复ack数据丢失，不是也会有上述问题**

因为服务是处于syn_received 状态，此时客户端重新发送的ack+序列号是一样的。所以重复发送是可以理解为幂等的效果

### TCP 第一次握手的 SYN 丢包了，会发生了什么？

当客户端发起的 TCP 第一次握手 SYN 包，在超时时间内没收到服务端的 ACK，就会在超时重传 SYN 数据包，每次超时重传的 RTO 是翻倍上涨的，直到 SYN 包的重传次数到达 `tcp_syn_retries` 值后，客户端不再发送 SYN 包。

### TCP 第二次握手的 SYN、ACK 丢包了，会发生什么？

![image-20230517204930009](/Users/11126518/Library/Application Support/typora-user-images/image-20230517204930009.png)

当 TCP 第二次握手 SYN、ACK 包丢了后，客户端 SYN 包会发生超时重传，服务端 SYN、ACK 也会发生超时重传。

客户端 SYN 包超时重传的最大次数，是由 tcp_syn_retries 决定的，默认值是 5 次；服务端 SYN、ACK 包时重传的最大次数，是由 tcp_synack_retries 决定的，默认值是 5 次。

### TCP 第三次握手的 ACK 包丢了，会发生什么？

![image-20230517205500015](/Users/11126518/Library/Application Support/typora-user-images/image-20230517205500015.png)

在建立 TCP 连接时，如果第三次握手的 ACK，服务端无法收到，则服务端就会短暂处于 `SYN_RECV` 状态，而客户端会处于 `ESTABLISHED` 状态。

由于服务端一直收不到 TCP 第三次握手的 ACK，则会一直重传 SYN、ACK 包，直到重传次数超过 `tcp_synack_retries` 值（默认值 5 次）后，服务端就会断开 TCP 连接。

而客户端则会有两种情况：

- 如果客户端没发送数据包，一直处于 `ESTABLISHED` 状态，然后经过 2 小时 11 分 15 秒才可以发现一个「死亡」连接，于是客户端连接就会断开连接。
- 如果客户端发送了数据包，一直没有收到服务端对该数据包的确认报文，则会一直重传该数据包，直到重传次数超过 `tcp_retries2` 值（默认值 15 次）后，客户端就会断开 TCP 连接。

### 什么是 SYN 攻击？如何避免 SYN 攻击？

在 TCP 三次握手的时候，Linux 内核会维护两个队列，分别是：

- 半连接队列，也称 SYN 队列；
- 全连接队列，也称 accept 队列；

避免 SYN 攻击方式，可以有以下四种方法：

- 调大 netdev_max_backlog；
- 增大 TCP 半连接队列；
- 开启 tcp_syncookies；
- 减少 SYN+ACK 重传次数

### 为什么挥手需要四次？

- 关闭连接时，客户端向服务端发送 `FIN` 时，仅仅表示客户端不再发送数据了但是还能接收数据。
- 服务端收到客户端的 `FIN` 报文时，先回一个 `ACK` 应答报文，而服务端可能还有数据需要处理和发送，等服务端不再发送数据时，才发送 `FIN` 报文给客户端来表示同意现在关闭连接。

**什么情况会出现三次挥手 **

因为TCP 延迟确认机制。 当发送没有携带数据的 ACK，它的网络效率也是很低的，因为它也有 40 个字节的 IP 头 和 TCP 头，但却没有携带数据报文。 为了解决 ACK 传输效率低问题，所以就衍生出了 **TCP 延迟确认**。 TCP 延迟确认的策略：

- 当有响应数据要发送时，ACK 会随着响应数据一起立刻发送给对方
- 当没有响应数据要发送时，ACK 将会延迟一段时间，以等待是否有响应数据可以一起发送
- 如果在延迟等待发送 ACK 期间，对方的第二个数据报文又到达了，这时就会立刻发送 ACK

### SYN 报文什么时候情况下会被丢弃？

客户端向服务端发起了连接，但是连接并没有建立起来，通过抓包分析发现，服务端是收到 SYN 报文了，但是并没有回复 SYN+ACK（TCP 第二次握手），说明 SYN 报文被服务端忽略了，然后客户端就一直在超时重传 SYN 报文，直到达到最大的重传次数。

 SYN 报文被丢弃的两种场景：

- 开启 tcp_tw_recycle 参数，并且在 NAT 环境下，造成 SYN 报文被丢弃
- TCP 两个队列满了（半连接队列和全连接队列），造成 SYN 报文被丢

### 已建立连接的TCP，收到SYN会发生什么？

大概意思是，一个已经建立的 TCP 连接，客户端中途宕机了，而服务端此时也没有数据要发送，一直处于 Established 状态，客户端恢复后，向服务端建立连接，此时服务端会怎么处理？

**1. 客户端的 SYN 报文里的端口号与历史连接不相同**

通过三次握手来建立新的连接

如果服务端发送了数据包给客户端，由于客户端的连接已经被关闭了，此时客户的内核就会回 RST 报文，服务端收到后就会释放连接。

如果服务端一直没有发送数据包给客户端，在超过一段时间后，TCP 保活机制就会启动，检测到客户端没有存活后，接着服务端就会释放掉该连接。

**2. 客户端的 SYN 报文里的端口号与历史连接相同**

处于 Established 状态的服务端，如果收到了客户端的 SYN 报文（注意此时的 SYN 报文其实是乱序的，因为 SYN 报文的初始化序列号其实是一个随机数），会回复一个携带了正确序列号和确认号的 ACK 报文，这个 ACK 被称之为 Challenge ACK。

接着，客户端收到这个 Challenge ACK，发现确认号（ack num）并不是自己期望收到的，于是就会回 RST 报文，服务端收到后，就会释放掉该连接。

### 四次挥手中收到乱序的 FIN 包会如何处理？

在 FIN_WAIT_2 状态时，如果收到乱序的 FIN 报文，那么就被会加入到「乱序队列」，并不会进入到 TIME_WAIT 状态。

等再次收到前面被网络延迟的数据包时，会判断乱序队列有没有数据，然后会检测乱序队列中是否有可用的数据，如果能在乱序队列中找到与当前报文的序列号保持的顺序的报文，就会看该报文是否有 FIN 标志，如果发现有 FIN 标志，这时才会进入 TIME_WAIT 状态。

### 在 TIME_WAIT 状态的 TCP 连接，收到 SYN 后会发生什么？

关键是要看 SYN 的「序列号和时间戳」是否合法，因为处于 TIME_WAIT 状态的连接收到 SYN 后，会判断 SYN 的「序列号和时间戳」是否合法，然后根据判断结果的不同做不同的处理。

> 收到合法 SYN

如果处于 TIME_WAIT 状态的连接收到「合法的 SYN 」后，**就会重用此四元组连接，跳过 2MSL 而转变为 SYN_RECV 状态，接着就能进行建立连接过程**。

>   收到非法的 SYN

如果处于 TIME_WAIT 状态的连接收到「非法的 SYN 」后，就会**再回复一个第四次挥手的 ACK 报文，客户端收到后，发现并不是自己期望收到确认号（ack num），就回 RST 报文给服务端**。

### 在 TIME_WAIT 状态，收到 RST 会断开连接吗？

- 如果 `net.ipv4.tcp_rfc1337` 参数为 0，则提前结束 TIME_WAIT 状态，释放连接。
- 如果 `net.ipv4.tcp_rfc1337` 参数为 1，则会丢掉该 RST 报文。

###  为什么 TIME_WAIT 等待的时间是 2MSL？

`MSL` 是 Maximum Segment Lifetime，**报文最大生存时间**。

MSL 与 TTL 的区别： MSL 的单位是时间，而 TTL 是经过路由跳数。所以 **MSL 应该要大于等于 TTL 消耗为 0 的时间**，以确保报文已被自然消亡

**TTL 的值一般是 64，Linux 将 MSL 设置为 30 秒，意味着 Linux 认为数据报文经过 64 个路由器的时间不会超过 30 秒，如果超过了，就认为报文已经消失在网络中了**。

TIME_WAIT 等待 2 倍的 MSL，比较合理的解释是： 网络中可能存在来自发送方的数据包，当这些发送方的数据包被接收方处理后又会向对方发送响应，所以**一来一回需要等待 2 倍的时间**。

### 为什么需要 TIME_WAIT 状态？

- 防止历史连接中的数据，被后面相同四元组的连接错误的接收；上一个连接关闭后，由于网络延迟，导致新建立的连接，收到了延迟后的数据。
- 保证「被动关闭连接」的一方，能被正确的关闭；如果客户端ack应答丢失，服务端会重新发送fin包，给客户端再次做确认

### 如果已经建立了连接，但是客户端突然出现故障了怎么办？

服务端是永远无法感知到客户端宕机这个事件的，也就是服务端的 TCP 连接将一直处于 `ESTABLISH` 状态，占用着系统资源。为了避免这种情况，TCP 搞了个**保活机制**

### 如果已经建立了连接，但是服务端的进程崩溃会发生什么？

当服务端的进程崩溃后，内核需要回收该进程的所有 TCP 连接资源，于是内核会发送第一次挥手 FIN 报文，后续的挥手过程也都是在内核完成，并不需要进程的参与，所以即使服务端的进程退出了，还是能与客户端完成 TCP 四次挥手的过程。

### 拔掉网线后， 原本的 TCP 连接还存在吗？

**1 拔掉网线后，有数据传输**

在等待一定时长后，服务端就会触发**超时重传**机制，重传未得到响应的数据报文。

- 在客户端拔掉网线后，如果服务端发送了数据报文，那么在服务端重传次数没有达到最大值之前，客户端就插回了网线，那么双方原本的 TCP 连接还是能正常存在，就好像什么事情都没有发生。
- 在客户端拔掉网线后，如果服务端发送了数据报文，在客户端插回网线之前，服务端重传次数达到了最大值时，服务端就会断开 TCP 连接。等到客户端插回网线后，向服务端发送了数据，因为服务端已经断开了与客户端相同四元组的 TCP 连接，所以就会回 RST 报文，客户端收到后就会断开 TCP 连接。至此， 双方的 TCP 连接都断开了。

#### 2 拔掉网线后，没有数据传输

- 如果双方都没有开启 TCP keepalive 机制，那么在客户端拔掉网线后，如果客户端一直不插回网线，那么客户端和服务端的 TCP 连接状态将会一直保持存在。
- 如果双方都开启了 TCP keepalive 机制，那么在客户端拔掉网线后，如果客户端一直不插回网线，TCP keepalive 机制会探测到对方的 TCP 连接没有存活，于是就会断开 TCP 连接。而如果在 TCP 探测期间，客户端插回了网线，那么双方原本的 TCP 连接还是能正常存在。

###  listen 时候参数 backlog 的意义？

- 半连接队列（SYN 队列）：接收到一个 SYN 建立连接请求，处于 SYN_RCVD 状态；
- 全连接队列（Accpet 队列）：已完成 TCP 三次握手过程，处于 ESTABLISHED 状态；

```
int listen (int socketfd, int backlog)
```

**现在通常认为 backlog 是 accept 队列。**

### 没有listen，为什么还能建立连接

客户端是可以自己连自己的形成连接（**TCP自连接**），也可以两个客户端同时向对方发出请求建立连接（**TCP同时打开**），这两个情况都有个共同点，就是**没有服务端参与，也就是没有 listen，就能 TCP 建立连接。**

###  accept 发生在三次握手的哪一步？

客户端 connect 成功返回是在第二次握手，服务端 accept 成功返回是在三次握手成功之后。

###  没有 accept，能建立 TCP 连接吗？

建立连接的过程中根本不需要`accept()`参与， 执行accept()只是为了从全连接队列里取出一条连接。

半连接队列是hash表（需要识别三次握手），全连接是个链表（就绪连接）。

### HTTPS 中 TLS 和 TCP 能同时握手吗？

1. HTTPS 是先进行 TCP 三次握手，再进行 TLSv1.2 四次握手

2. HTTPS 中的 TLS 握手过程可以同时进行三次握手，这个场景是可能存在到，但是在没有说任何前提条件，而说这句话就等于耍流氓。需要下面这两个条件同时满足才可以：

- **客户端和服务端都开启了 TCP Fast Open 功能，且 TLS 版本是 1.3；**
- **客户端和服务端已经完成过一次通信；**

## 重传机制、滑动窗口、流量控制、拥塞控制

TCP 是通过序列号、确认应答、重发控制、连接管理以及窗口控制等机制实现可靠性传输的。

今天，将重点介绍 TCP 的**重传机制、滑动窗口、流量控制、拥塞控制。**

![img](https://cdn.xiaolincoding.com/gh/xiaolincoder/ImageHost2/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/TCP-%E5%8F%AF%E9%9D%A0%E7%89%B9%E6%80%A7/3.jpg?image_process=watermark,text_5YWs5LyX5Y-377ya5bCP5p6XY29kaW5n,type_ZnpsdHpoaw,x_10,y_10,g_se,size_20,color_0000CD,t_70,fill_0)

### 滑动窗口

我们都知道 TCP 是每发送一个数据，都要进行一次确认应答。当上一个数据包收到了应答了， 再发送下一个。所以，这样的传输方式有一个缺点：数据包的**往返时间越长，通信的效率就越低**。

TCP 头里有一个字段叫 `Window`，也就是窗口大小。

**这个字段是接收端告诉发送端自己还有多少缓冲区可以接收数据。于是发送端就可以根据这个接收端的处理能力来发送数据，而不会导致接收端处理不过来。**

### 流量控制

为了防止这种情况发生，TCP 规定是不允许同时减少缓存又收缩窗口的，而是采用先收缩窗口，过段时间再减少缓存，这样就可以避免了丢包情况。

#### 窗口关闭

窗口探测的次数一般为 3 次，每次大约 30-60 秒（不同的实现可能会不一样）。如果 3 次过后接收窗口还是 0 的话，有的 TCP 实现就会发 `RST` 报文来中断连接。

### 拥塞控制

>  为什么要有拥塞控制呀，不是有流量控制了吗？

流量控制是避免「发送方」的数据填满「接收方」的缓存，但是并不知道网络的中发生了什么。

只要「发送方」没有在规定时间内接收到 ACK 应答报文，也就是**发生了超时重传，就会认为网络出现了拥塞。**

拥塞控制主要是四个算法：

- 慢启动 (慢启动算法，发包的个数是**指数性的增长**)
- 拥塞避免(拥塞避免算法就是将原本慢启动算法的指数增长变成了线性增长，还是增长阶段，但是增长速度缓慢了一些)
- 拥塞发生(发生快速重传的拥塞发生算法)
- 快速恢复（快速恢复是拥塞发生后慢启动的优化，其首要目的仍然是降低 cwnd 来减缓拥塞，所以必然会出现 cwnd 从大到小的改变）

### TCP 协议有什么缺陷？

- 升级 TCP 的工作很困难
- TCP 建立连接的延迟（先三次握手， TLS 四次握手）
- TCP 存在队头阻塞问题（TCP 是字节流协议，**TCP 层必须保证收到的字节数据是完整且有序的**，如果序列号较低的 TCP 段在网络传输中丢失了，即使序列号较高的 TCP 段已经被接收了，应用层也无法从内核中读取到这部分数据）
- 网络迁移需要重新建立 TCP 连接（当移动设备的网络从 4G 切换到 WIFI 时，意味着 IP 地址变化了，那么就必须要断开连接，然后重新建立 TCP 连接）

### 如何基于 UDP 协议实现可靠传输

![image-20230519183202129](/Users/11126518/Library/Application Support/typora-user-images/image-20230519183202129.png)

### TCP 和 UDP 可以使用同一个端口吗

可以。传输层有两个传输协议分别是 TCP 和 UDP，在内核中是两个完全独立的软件模块

#### 多个 TCP 服务进程可以绑定同一个端口吗

如果两个 TCP 服务进程同时绑定的 IP 地址和端口都相同，那么执行 bind() 时候就会出错，错误是“Address already in use”

#### 重启 TCP 服务进程时，为什么会有“Address in use”的报错信息？

当 TCP 服务进程重启时，服务端会出现 TIME_WAIT 状态的连接，TIME_WAIT 状态的连接使用的 IP+PORT 仍然被认为是一个有效的 IP+PORT 组合，相同机器上不能够在该 IP+PORT 组合上进行绑定，那么执行 bind() 函数的时候，就会返回了 Address already in use 的错误

> 重启 TCP 服务进程时，如何避免“Address in use”的报错信息？

我们可以在调用 bind 前，对 socket 设置 SO_REUSEADDR 属性，可以解决这个问题。

### 客户端 TCP 连接 TIME_WAIT 状态过多，会导致端口资源耗尽而无法建立新的连接吗？

如果客户端都是与同一个服务器（目标地址和目标端口一样）建立连接，那么如果客户端 TIME_WAIT 状态的连接过多，当端口资源被耗尽，就无法与这个服务器再建立连接了。

### 服务端没有 listen，客户端发起连接建立，会发生什么？

服务端如果只 bind 了 IP 地址和端口，而没有调用 listen 的话，然后客户端对服务端发起了连接建立，服务端会回 RST 报文

### 没有 accept，能建立 TCP 连接吗？

- 每一个`socket`执行`listen`时，内核都会自动创建一个半连接队列和全连接队列。
- 第三次握手前，TCP连接会放在半连接队列中，直到第三次握手到来，才会被放到全连接队列中。
- `accept方法`只是为了从全连接队列中拿出一条连接，本身跟三次握手几乎**毫无关系**。
- 出于效率考虑，虽然都叫队列，但半连接队列其实被设计成了**哈希表**，而全连接队列本质是链表。
- 全连接队列满了，再来第三次握手也会丢弃，此时如果`tcp_abort_on_overflow=1`，还会直接发`RST`给客户端。
- 半连接队列满了，可能是因为受到了`SYN Flood`攻击，可以设置`tcp_syncookies`，绕开半连接队列。
- 客户端没有半连接队列和全连接队列，但有一个**全局hash**，可以通过它实现自连接或TCP同时打开。

### 如何优化 TCP?

![image-20230518105045495](/Users/11126518/Library/Application Support/typora-user-images/image-20230518105045495.png)

### TCP 是面向字节流的协议，UDP 是面向报文的协议？这里的「面向字节流」和「面向报文」该如何理解。

当用户消息通过 UDP 协议传输时，**操作系统不会对消息进行拆分**，在组装好 UDP 头部后就交给网络层来处理，所以发出去的 UDP 报文中的数据部分就是完整的用户消息，也就是**每个 UDP 报文就是一个用户消息的边界**，这样接收方在接收到 UDP 报文后，读一个 UDP 报文就能读取到完整的用户消息。

当用户消息通过 TCP 协议传输时，**消息可能会被操作系统分组成多个的 TCP 报文**，也就是一个完整的用户消息被拆分成多个 TCP 报文进行传输。

### 1.什么是 TCP 粘包

TCP粘包：指A端发送2次请求，期望B端分2次读取，实际B端一次性获取了2条数据，数据未根据期望正确分割的一种现象。

- 造成TCP粘包的原因：

  1. TCP默认使用Nagle算法发送请求 Nagle算法主要为了减少网络中包数量，Nagle算法主要逻辑：

     - 收集多个小分组，在一个确认到来时一起发送
     - 只有上一个分组得到确认，才会发送下一个分组

     Nagle算法造成了发送方可能会出现粘包问题

  2. TCP接收数据包到缓存的速度>应用程序从缓存中读取数据包的速度 TCP接收的数据包会先保存到缓存中，当TCP接收数据包到缓存的速度>应用程序从缓存中读取数据包的速度时，存在多个包被缓存，应用程序就有可能读取到多个首尾相接粘到一起的包。

#### 2. TCP半包：

- 造成TCP半包的原因：
  - 发送方每次写入数据 > 套接字（Socket）缓冲区大小
  - 发送的数据大于协议的 MTU (Maximum Transmission Unit，最大传输单元)，因此必须拆包

#### 3. 为什么TCP没有解决半包、粘包的问题

由于TCP是面向连接的传输协议，TCP传输的数据是以流的形式，而流数据是没有明确的开始结尾边界，所以TCP也没办法判断哪一段流属于一个消息。 而UDP是没有半包、粘包的问题，因为UPD是面向消息的，它有边界协议，可以根据消息的格式区分消息的开始和结尾。

UDP和TCP两个发送消息就好像一个用桶运水，一个用水管运水，用水管运水的你是没办法区分那部分的水是属于哪一桶的。

#### **应用层如何解决半包粘包的问题**

上面部分我们知道UDP是没有半包粘包的问题的，因为它有边界协议，消息是有格式的。所以我们应用层的解决方案也是在这一思路上展开，解决半包粘包的问题其实就是定义消息边界的问题。

#### **应用层定义消息边界的几种方式**

##### i. 定长消息(fix length)

发送端和接收端约定消息长度, 缺点: 消息很短时, 效率很低, 浪费带宽

每次发送固定缓冲区大小数据。客户端和服务器约定每次发送请求的大小。例如客户端发送 1024 个字节，服务器接受 1024 个字节。

这样虽然可以解决粘包的问题，但是如果发送的数据小于 1024 个字节，就会导致数据内存冗余和浪费；且如果发送请求大于 1024 字节，会出现半包的问题，也就是数据接收的不完整。

##### ii. 特殊标志作为结束标志(delimiter based)

ftp协议就是这种方式, 缺点: 消息内容不能含有这种特殊标志, 会提前终止消息

##### iii. 定长包头中包含请求长度(length field based frame decoder)

每次都要尽可能的去读数据, 读到之后分析:

先取包头, 在包头里分析出包体的长度, 如果包头都不够, 要继续读数据拼接在已有的数据后面, 继续分析包体的长度, 拿到包体的长度就从包头结束的位置截取包体, 依次读取, 直到对方关闭

### TCP连接中出现RST的情况

- [1 端口未打开](http://my.oschina.net/costaxu/blog/127394#OSC_h2_1)
- [2 请求超时](http://my.oschina.net/costaxu/blog/127394#OSC_h2_2)
- [3 提前关闭](http://my.oschina.net/costaxu/blog/127394#OSC_h2_3)
- [4 在一个已关闭的socket上收到数据](http://my.oschina.net/costaxu/blog/127394#OSC_h2_4)
- 5.用于拒绝一个非法连接

### reference

[为什么 HTTP1.1 不能实现多路复用](https://github.com/Advanced-Frontend/Daily-Interview-Question/issues/290)

一定要看http://blog.chinaunix.net/uid-27105712-id-5793734.html

[tcp/ip之三次握手](https://www.huaweicloud.com/articles/f05a25dad9650e6cc999dd3dda0e84ae.html)

